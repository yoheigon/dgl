{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c917d78f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'author': 17431, 'paper': 12499, 'subject': 73},\n",
      "      num_edges={('author', 'writing', 'paper'): 37055, ('paper', 'cited', 'paper'): 30789, ('paper', 'citing', 'paper'): 30789, ('paper', 'is-about', 'subject'): 12499, ('paper', 'written-by', 'author'): 37055, ('subject', 'has', 'paper'): 12499},\n",
      "      metagraph=[('author', 'paper', 'writing'), ('paper', 'paper', 'cited'), ('paper', 'paper', 'citing'), ('paper', 'subject', 'is-about'), ('paper', 'author', 'written-by'), ('subject', 'paper', 'has')])\n",
      "----------------\n",
      "Minibatch Training with HGT\n",
      "setting fanout as 16\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Epoch: 5 LR: 0.00006 Loss 2.6703, Train Acc 0.0463, Val Acc 0.0600 (Best 0.0600), Test Acc 0.0460 (Best 0.0460)\n",
      "Epoch: 10 LR: 0.00011 Loss 2.6106, Train Acc 0.0487, Val Acc 0.0600 (Best 0.0600), Test Acc 0.0480 (Best 0.0460)\n",
      "Epoch: 15 LR: 0.00019 Loss 2.5242, Train Acc 0.1388, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1251 (Best 0.1251)\n",
      "Epoch: 20 LR: 0.00029 Loss 2.4642, Train Acc 0.1450, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1274 (Best 0.1251)\n",
      "Epoch: 25 LR: 0.00041 Loss 2.4302, Train Acc 0.1388, Val Acc 0.1500 (Best 0.1500), Test Acc 0.1429 (Best 0.1429)\n",
      "Epoch: 30 LR: 0.00053 Loss 2.3405, Train Acc 0.3125, Val Acc 0.2800 (Best 0.2800), Test Acc 0.2974 (Best 0.2974)\n",
      "Epoch: 35 LR: 0.00066 Loss 2.1113, Train Acc 0.3212, Val Acc 0.2900 (Best 0.2900), Test Acc 0.3149 (Best 0.3149)\n",
      "Epoch: 40 LR: 0.00077 Loss 1.8969, Train Acc 0.3787, Val Acc 0.2700 (Best 0.2900), Test Acc 0.3457 (Best 0.3149)\n",
      "Epoch: 45 LR: 0.00087 Loss 1.6646, Train Acc 0.4050, Val Acc 0.2800 (Best 0.2900), Test Acc 0.3806 (Best 0.3149)\n",
      "Epoch: 50 LR: 0.00095 Loss 1.5632, Train Acc 0.4750, Val Acc 0.3400 (Best 0.3400), Test Acc 0.4120 (Best 0.4120)\n",
      "Epoch: 55 LR: 0.00099 Loss 1.4388, Train Acc 0.5375, Val Acc 0.3700 (Best 0.3700), Test Acc 0.4249 (Best 0.4249)\n",
      "Epoch: 60 LR: 0.00100 Loss 1.3152, Train Acc 0.5700, Val Acc 0.3800 (Best 0.3800), Test Acc 0.4357 (Best 0.4357)\n",
      "Epoch: 65 LR: 0.00100 Loss 1.2306, Train Acc 0.5725, Val Acc 0.4400 (Best 0.4400), Test Acc 0.4341 (Best 0.4341)\n",
      "Epoch: 70 LR: 0.00098 Loss 1.0424, Train Acc 0.6650, Val Acc 0.4200 (Best 0.4400), Test Acc 0.4081 (Best 0.4341)\n",
      "Epoch: 75 LR: 0.00097 Loss 0.8908, Train Acc 0.7550, Val Acc 0.4200 (Best 0.4400), Test Acc 0.3996 (Best 0.4341)\n",
      "Epoch: 80 LR: 0.00095 Loss 0.7245, Train Acc 0.8062, Val Acc 0.3900 (Best 0.4400), Test Acc 0.3842 (Best 0.4341)\n",
      "Epoch: 85 LR: 0.00092 Loss 0.6223, Train Acc 0.8525, Val Acc 0.3800 (Best 0.4400), Test Acc 0.3624 (Best 0.4341)\n",
      "Epoch: 90 LR: 0.00088 Loss 0.4891, Train Acc 0.9062, Val Acc 0.4100 (Best 0.4400), Test Acc 0.3721 (Best 0.4341)\n",
      "Epoch: 95 LR: 0.00085 Loss 0.4340, Train Acc 0.9325, Val Acc 0.4400 (Best 0.4400), Test Acc 0.3697 (Best 0.4341)\n",
      "Epoch: 100 LR: 0.00080 Loss 0.3382, Train Acc 0.9600, Val Acc 0.4200 (Best 0.4400), Test Acc 0.3614 (Best 0.4341)\n",
      "Epoch: 105 LR: 0.00076 Loss 0.2836, Train Acc 0.9750, Val Acc 0.3900 (Best 0.4400), Test Acc 0.3592 (Best 0.4341)\n",
      "Epoch: 110 LR: 0.00071 Loss 0.2357, Train Acc 0.9812, Val Acc 0.4200 (Best 0.4400), Test Acc 0.3643 (Best 0.4341)\n",
      "Epoch: 115 LR: 0.00065 Loss 0.1871, Train Acc 0.9912, Val Acc 0.4100 (Best 0.4400), Test Acc 0.3642 (Best 0.4341)\n",
      "Epoch: 120 LR: 0.00060 Loss 0.1522, Train Acc 0.9987, Val Acc 0.3700 (Best 0.4400), Test Acc 0.3588 (Best 0.4341)\n",
      "Epoch: 125 LR: 0.00054 Loss 0.1210, Train Acc 1.0000, Val Acc 0.3600 (Best 0.4400), Test Acc 0.3527 (Best 0.4341)\n",
      "Epoch: 130 LR: 0.00049 Loss 0.0975, Train Acc 1.0000, Val Acc 0.3500 (Best 0.4400), Test Acc 0.3514 (Best 0.4341)\n",
      "Epoch: 135 LR: 0.00043 Loss 0.0775, Train Acc 1.0000, Val Acc 0.3500 (Best 0.4400), Test Acc 0.3508 (Best 0.4341)\n",
      "Epoch: 140 LR: 0.00038 Loss 0.0651, Train Acc 1.0000, Val Acc 0.3600 (Best 0.4400), Test Acc 0.3537 (Best 0.4341)\n",
      "Epoch: 145 LR: 0.00032 Loss 0.0555, Train Acc 1.0000, Val Acc 0.3800 (Best 0.4400), Test Acc 0.3537 (Best 0.4341)\n",
      "Epoch: 150 LR: 0.00027 Loss 0.0485, Train Acc 1.0000, Val Acc 0.3800 (Best 0.4400), Test Acc 0.3538 (Best 0.4341)\n",
      "Epoch: 155 LR: 0.00022 Loss 0.0437, Train Acc 1.0000, Val Acc 0.3600 (Best 0.4400), Test Acc 0.3520 (Best 0.4341)\n",
      "Epoch: 160 LR: 0.00018 Loss 0.0399, Train Acc 1.0000, Val Acc 0.3800 (Best 0.4400), Test Acc 0.3510 (Best 0.4341)\n",
      "Epoch: 165 LR: 0.00014 Loss 0.0376, Train Acc 1.0000, Val Acc 0.3700 (Best 0.4400), Test Acc 0.3526 (Best 0.4341)\n",
      "Epoch: 170 LR: 0.00010 Loss 0.0359, Train Acc 1.0000, Val Acc 0.3700 (Best 0.4400), Test Acc 0.3512 (Best 0.4341)\n",
      "Epoch: 175 LR: 0.00007 Loss 0.0348, Train Acc 1.0000, Val Acc 0.3700 (Best 0.4400), Test Acc 0.3523 (Best 0.4341)\n",
      "Epoch: 180 LR: 0.00004 Loss 0.0353, Train Acc 1.0000, Val Acc 0.3700 (Best 0.4400), Test Acc 0.3518 (Best 0.4341)\n",
      "Epoch: 185 LR: 0.00002 Loss 0.0338, Train Acc 1.0000, Val Acc 0.3700 (Best 0.4400), Test Acc 0.3507 (Best 0.4341)\n",
      "Epoch: 190 LR: 0.00001 Loss 0.0337, Train Acc 1.0000, Val Acc 0.3700 (Best 0.4400), Test Acc 0.3507 (Best 0.4341)\n",
      "Epoch: 195 LR: 0.00000 Loss 0.0334, Train Acc 1.0000, Val Acc 0.3700 (Best 0.4400), Test Acc 0.3505 (Best 0.4341)\n",
      "Epoch: 200 LR: 0.00000 Loss 0.0333, Train Acc 1.0000, Val Acc 0.3700 (Best 0.4400), Test Acc 0.3508 (Best 0.4341)\n",
      "----------------\n",
      "Fullbatch Training with HGT\n",
      "Epoch: 5 LR: 0.00006 Loss 2.7450, Train Acc 0.0787, Val Acc 0.0900 (Best 0.0900), Test Acc 0.0853 (Best 0.0853)\n",
      "Epoch: 10 LR: 0.00011 Loss 2.6825, Train Acc 0.1037, Val Acc 0.1100 (Best 0.1100), Test Acc 0.0913 (Best 0.0913)\n",
      "Epoch: 15 LR: 0.00019 Loss 2.5333, Train Acc 0.1375, Val Acc 0.1300 (Best 0.1300), Test Acc 0.1380 (Best 0.1380)\n",
      "Epoch: 20 LR: 0.00029 Loss 2.4525, Train Acc 0.2037, Val Acc 0.1800 (Best 0.1800), Test Acc 0.1839 (Best 0.1839)\n",
      "Epoch: 25 LR: 0.00041 Loss 2.3839, Train Acc 0.2300, Val Acc 0.2200 (Best 0.2200), Test Acc 0.2271 (Best 0.2271)\n",
      "Epoch: 30 LR: 0.00053 Loss 2.3019, Train Acc 0.2937, Val Acc 0.3000 (Best 0.3000), Test Acc 0.2764 (Best 0.2764)\n",
      "Epoch: 35 LR: 0.00066 Loss 2.0249, Train Acc 0.3413, Val Acc 0.2800 (Best 0.3000), Test Acc 0.3303 (Best 0.2764)\n",
      "Epoch: 40 LR: 0.00077 Loss 1.7485, Train Acc 0.3950, Val Acc 0.2900 (Best 0.3000), Test Acc 0.3712 (Best 0.2764)\n",
      "Epoch: 45 LR: 0.00087 Loss 1.5477, Train Acc 0.4588, Val Acc 0.3600 (Best 0.3600), Test Acc 0.4139 (Best 0.4139)\n",
      "Epoch: 50 LR: 0.00095 Loss 1.3753, Train Acc 0.5175, Val Acc 0.4600 (Best 0.4600), Test Acc 0.4495 (Best 0.4495)\n",
      "Epoch: 55 LR: 0.00099 Loss 1.2362, Train Acc 0.5550, Val Acc 0.5100 (Best 0.5100), Test Acc 0.4694 (Best 0.4694)\n",
      "Epoch: 60 LR: 0.00100 Loss 1.1513, Train Acc 0.5825, Val Acc 0.4600 (Best 0.5100), Test Acc 0.4589 (Best 0.4694)\n",
      "Epoch: 65 LR: 0.00100 Loss 1.0391, Train Acc 0.6400, Val Acc 0.4000 (Best 0.5100), Test Acc 0.4625 (Best 0.4694)\n",
      "Epoch: 70 LR: 0.00098 Loss 0.8947, Train Acc 0.6600, Val Acc 0.4600 (Best 0.5100), Test Acc 0.4416 (Best 0.4694)\n",
      "Epoch: 75 LR: 0.00097 Loss 0.7698, Train Acc 0.7613, Val Acc 0.4400 (Best 0.5100), Test Acc 0.4452 (Best 0.4694)\n",
      "Epoch: 80 LR: 0.00095 Loss 0.6615, Train Acc 0.8087, Val Acc 0.4500 (Best 0.5100), Test Acc 0.4446 (Best 0.4694)\n",
      "Epoch: 85 LR: 0.00092 Loss 0.5703, Train Acc 0.8037, Val Acc 0.4100 (Best 0.5100), Test Acc 0.4078 (Best 0.4694)\n",
      "Epoch: 90 LR: 0.00088 Loss 0.4603, Train Acc 0.8788, Val Acc 0.4400 (Best 0.5100), Test Acc 0.4279 (Best 0.4694)\n",
      "Epoch: 95 LR: 0.00085 Loss 0.3931, Train Acc 0.9000, Val Acc 0.4300 (Best 0.5100), Test Acc 0.4145 (Best 0.4694)\n",
      "Epoch: 100 LR: 0.00080 Loss 0.3185, Train Acc 0.9262, Val Acc 0.3700 (Best 0.5100), Test Acc 0.4187 (Best 0.4694)\n",
      "Epoch: 105 LR: 0.00076 Loss 0.2799, Train Acc 0.9463, Val Acc 0.3800 (Best 0.5100), Test Acc 0.4106 (Best 0.4694)\n",
      "Epoch: 110 LR: 0.00071 Loss 0.2017, Train Acc 0.9800, Val Acc 0.4000 (Best 0.5100), Test Acc 0.4065 (Best 0.4694)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 115 LR: 0.00065 Loss 0.1681, Train Acc 0.9900, Val Acc 0.4100 (Best 0.5100), Test Acc 0.4068 (Best 0.4694)\n",
      "Epoch: 120 LR: 0.00060 Loss 0.1254, Train Acc 0.9962, Val Acc 0.3900 (Best 0.5100), Test Acc 0.3914 (Best 0.4694)\n",
      "Epoch: 125 LR: 0.00054 Loss 0.1024, Train Acc 0.9962, Val Acc 0.4000 (Best 0.5100), Test Acc 0.3991 (Best 0.4694)\n",
      "Epoch: 130 LR: 0.00049 Loss 0.0998, Train Acc 0.9975, Val Acc 0.4100 (Best 0.5100), Test Acc 0.3981 (Best 0.4694)\n",
      "Epoch: 135 LR: 0.00043 Loss 0.0865, Train Acc 0.9987, Val Acc 0.4100 (Best 0.5100), Test Acc 0.3961 (Best 0.4694)\n",
      "Epoch: 140 LR: 0.00038 Loss 0.0629, Train Acc 0.9987, Val Acc 0.4100 (Best 0.5100), Test Acc 0.4045 (Best 0.4694)\n",
      "Epoch: 145 LR: 0.00032 Loss 0.0513, Train Acc 0.9987, Val Acc 0.3900 (Best 0.5100), Test Acc 0.4025 (Best 0.4694)\n",
      "Epoch: 150 LR: 0.00027 Loss 0.0460, Train Acc 1.0000, Val Acc 0.3900 (Best 0.5100), Test Acc 0.3961 (Best 0.4694)\n",
      "Epoch: 155 LR: 0.00022 Loss 0.0402, Train Acc 1.0000, Val Acc 0.4000 (Best 0.5100), Test Acc 0.3952 (Best 0.4694)\n",
      "Epoch: 160 LR: 0.00018 Loss 0.0344, Train Acc 1.0000, Val Acc 0.4100 (Best 0.5100), Test Acc 0.3993 (Best 0.4694)\n",
      "Epoch: 165 LR: 0.00014 Loss 0.0325, Train Acc 1.0000, Val Acc 0.4100 (Best 0.5100), Test Acc 0.3973 (Best 0.4694)\n",
      "Epoch: 170 LR: 0.00010 Loss 0.0299, Train Acc 1.0000, Val Acc 0.4000 (Best 0.5100), Test Acc 0.3981 (Best 0.4694)\n",
      "Epoch: 175 LR: 0.00007 Loss 0.0286, Train Acc 1.0000, Val Acc 0.4100 (Best 0.5100), Test Acc 0.3980 (Best 0.4694)\n",
      "Epoch: 180 LR: 0.00004 Loss 0.0260, Train Acc 1.0000, Val Acc 0.4000 (Best 0.5100), Test Acc 0.3981 (Best 0.4694)\n",
      "Epoch: 185 LR: 0.00002 Loss 0.0263, Train Acc 1.0000, Val Acc 0.4000 (Best 0.5100), Test Acc 0.3973 (Best 0.4694)\n",
      "Epoch: 190 LR: 0.00001 Loss 0.0263, Train Acc 1.0000, Val Acc 0.4000 (Best 0.5100), Test Acc 0.3973 (Best 0.4694)\n",
      "Epoch: 195 LR: 0.00000 Loss 0.0248, Train Acc 1.0000, Val Acc 0.4000 (Best 0.5100), Test Acc 0.3977 (Best 0.4694)\n",
      "Epoch: 200 LR: 0.00000 Loss 0.0260, Train Acc 1.0000, Val Acc 0.4000 (Best 0.5100), Test Acc 0.3976 (Best 0.4694)\n",
      "----------------\n",
      "Fullbatch Training with RGCN\n",
      "Epoch: 5 LR: 0.00006 Loss 2.6517, Train Acc 0.0700, Val Acc 0.0600 (Best 0.0600), Test Acc 0.0598 (Best 0.0598)\n",
      "Epoch: 10 LR: 0.00011 Loss 2.6429, Train Acc 0.0962, Val Acc 0.0900 (Best 0.0900), Test Acc 0.0880 (Best 0.0880)\n",
      "Epoch: 15 LR: 0.00019 Loss 2.6276, Train Acc 0.1762, Val Acc 0.1400 (Best 0.1400), Test Acc 0.1598 (Best 0.1598)\n",
      "Epoch: 20 LR: 0.00029 Loss 2.6031, Train Acc 0.1950, Val Acc 0.1900 (Best 0.1900), Test Acc 0.1920 (Best 0.1920)\n",
      "Epoch: 25 LR: 0.00041 Loss 2.5664, Train Acc 0.2050, Val Acc 0.2000 (Best 0.2000), Test Acc 0.1995 (Best 0.1995)\n",
      "Epoch: 30 LR: 0.00053 Loss 2.5124, Train Acc 0.2138, Val Acc 0.2100 (Best 0.2100), Test Acc 0.2055 (Best 0.2055)\n",
      "Epoch: 35 LR: 0.00066 Loss 2.4333, Train Acc 0.2450, Val Acc 0.2300 (Best 0.2300), Test Acc 0.2385 (Best 0.2385)\n",
      "Epoch: 40 LR: 0.00077 Loss 2.3217, Train Acc 0.3063, Val Acc 0.2600 (Best 0.2600), Test Acc 0.2822 (Best 0.2822)\n",
      "Epoch: 45 LR: 0.00087 Loss 2.1787, Train Acc 0.3375, Val Acc 0.2800 (Best 0.2800), Test Acc 0.3111 (Best 0.3111)\n",
      "Epoch: 50 LR: 0.00095 Loss 2.0204, Train Acc 0.3688, Val Acc 0.3100 (Best 0.3100), Test Acc 0.3263 (Best 0.3263)\n",
      "Epoch: 55 LR: 0.00099 Loss 1.8705, Train Acc 0.3900, Val Acc 0.3300 (Best 0.3300), Test Acc 0.3433 (Best 0.3433)\n",
      "Epoch: 60 LR: 0.00100 Loss 1.7522, Train Acc 0.3875, Val Acc 0.3600 (Best 0.3600), Test Acc 0.3560 (Best 0.3560)\n",
      "Epoch: 65 LR: 0.00100 Loss 1.6654, Train Acc 0.4125, Val Acc 0.3700 (Best 0.3700), Test Acc 0.3666 (Best 0.3666)\n",
      "Epoch: 70 LR: 0.00098 Loss 1.5997, Train Acc 0.4487, Val Acc 0.3700 (Best 0.3700), Test Acc 0.3694 (Best 0.3666)\n",
      "Epoch: 75 LR: 0.00097 Loss 1.5468, Train Acc 0.4825, Val Acc 0.3700 (Best 0.3700), Test Acc 0.3703 (Best 0.3666)\n",
      "Epoch: 80 LR: 0.00095 Loss 1.5022, Train Acc 0.4963, Val Acc 0.3800 (Best 0.3800), Test Acc 0.3767 (Best 0.3767)\n",
      "Epoch: 85 LR: 0.00092 Loss 1.4631, Train Acc 0.5113, Val Acc 0.3700 (Best 0.3800), Test Acc 0.3791 (Best 0.3767)\n",
      "Epoch: 90 LR: 0.00088 Loss 1.4277, Train Acc 0.5238, Val Acc 0.3800 (Best 0.3800), Test Acc 0.3798 (Best 0.3767)\n",
      "Epoch: 95 LR: 0.00085 Loss 1.3949, Train Acc 0.5325, Val Acc 0.3800 (Best 0.3800), Test Acc 0.3805 (Best 0.3767)\n",
      "Epoch: 100 LR: 0.00080 Loss 1.3643, Train Acc 0.5425, Val Acc 0.3800 (Best 0.3800), Test Acc 0.3818 (Best 0.3767)\n",
      "Epoch: 105 LR: 0.00076 Loss 1.3355, Train Acc 0.5500, Val Acc 0.3800 (Best 0.3800), Test Acc 0.3824 (Best 0.3767)\n",
      "Epoch: 110 LR: 0.00071 Loss 1.3085, Train Acc 0.5587, Val Acc 0.3800 (Best 0.3800), Test Acc 0.3843 (Best 0.3767)\n",
      "Epoch: 115 LR: 0.00065 Loss 1.2834, Train Acc 0.5713, Val Acc 0.3800 (Best 0.3800), Test Acc 0.3860 (Best 0.3767)\n",
      "Epoch: 120 LR: 0.00060 Loss 1.2602, Train Acc 0.5763, Val Acc 0.3700 (Best 0.3800), Test Acc 0.3878 (Best 0.3767)\n",
      "Epoch: 125 LR: 0.00054 Loss 1.2391, Train Acc 0.5875, Val Acc 0.3600 (Best 0.3800), Test Acc 0.3899 (Best 0.3767)\n",
      "Epoch: 130 LR: 0.00049 Loss 1.2200, Train Acc 0.5987, Val Acc 0.3600 (Best 0.3800), Test Acc 0.3901 (Best 0.3767)\n",
      "Epoch: 135 LR: 0.00043 Loss 1.2029, Train Acc 0.6162, Val Acc 0.3700 (Best 0.3800), Test Acc 0.3906 (Best 0.3767)\n",
      "Epoch: 140 LR: 0.00038 Loss 1.1879, Train Acc 0.6263, Val Acc 0.3800 (Best 0.3800), Test Acc 0.3910 (Best 0.3767)\n",
      "Epoch: 145 LR: 0.00032 Loss 1.1748, Train Acc 0.6275, Val Acc 0.3900 (Best 0.3900), Test Acc 0.3914 (Best 0.3914)\n",
      "Epoch: 150 LR: 0.00027 Loss 1.1637, Train Acc 0.6288, Val Acc 0.3900 (Best 0.3900), Test Acc 0.3928 (Best 0.3914)\n",
      "Epoch: 155 LR: 0.00022 Loss 1.1544, Train Acc 0.6350, Val Acc 0.3800 (Best 0.3900), Test Acc 0.3933 (Best 0.3914)\n",
      "Epoch: 160 LR: 0.00018 Loss 1.1469, Train Acc 0.6438, Val Acc 0.3800 (Best 0.3900), Test Acc 0.3943 (Best 0.3914)\n",
      "Epoch: 165 LR: 0.00014 Loss 1.1409, Train Acc 0.6488, Val Acc 0.3800 (Best 0.3900), Test Acc 0.3945 (Best 0.3914)\n",
      "Epoch: 170 LR: 0.00010 Loss 1.1363, Train Acc 0.6500, Val Acc 0.3700 (Best 0.3900), Test Acc 0.3946 (Best 0.3914)\n",
      "Epoch: 175 LR: 0.00007 Loss 1.1330, Train Acc 0.6513, Val Acc 0.3700 (Best 0.3900), Test Acc 0.3947 (Best 0.3914)\n",
      "Epoch: 180 LR: 0.00004 Loss 1.1308, Train Acc 0.6538, Val Acc 0.3700 (Best 0.3900), Test Acc 0.3947 (Best 0.3914)\n",
      "Epoch: 185 LR: 0.00002 Loss 1.1294, Train Acc 0.6538, Val Acc 0.3700 (Best 0.3900), Test Acc 0.3949 (Best 0.3914)\n",
      "Epoch: 190 LR: 0.00001 Loss 1.1286, Train Acc 0.6538, Val Acc 0.3700 (Best 0.3900), Test Acc 0.3949 (Best 0.3914)\n",
      "Epoch: 195 LR: 0.00000 Loss 1.1284, Train Acc 0.6538, Val Acc 0.3700 (Best 0.3900), Test Acc 0.3949 (Best 0.3914)\n",
      "Epoch: 200 LR: 0.00000 Loss 1.1283, Train Acc 0.6538, Val Acc 0.3700 (Best 0.3900), Test Acc 0.3949 (Best 0.3914)\n",
      "----------------\n",
      "Fullbatch Training with MLP\n",
      "Epoch: 5 LR: 0.00006 Loss 2.6360, Train Acc 0.0463, Val Acc 0.0400 (Best 0.0400), Test Acc 0.0391 (Best 0.0391)\n",
      "Epoch: 10 LR: 0.00011 Loss 2.6348, Train Acc 0.0650, Val Acc 0.0400 (Best 0.0400), Test Acc 0.0545 (Best 0.0391)\n",
      "Epoch: 15 LR: 0.00019 Loss 2.6327, Train Acc 0.1400, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1227 (Best 0.1227)\n",
      "Epoch: 20 LR: 0.00029 Loss 2.6293, Train Acc 0.1388, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1251 (Best 0.1227)\n",
      "Epoch: 25 LR: 0.00041 Loss 2.6241, Train Acc 0.1388, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1251 (Best 0.1227)\n",
      "Epoch: 30 LR: 0.00053 Loss 2.6169, Train Acc 0.1388, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1251 (Best 0.1227)\n",
      "Epoch: 35 LR: 0.00066 Loss 2.6070, Train Acc 0.1388, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1251 (Best 0.1227)\n",
      "Epoch: 40 LR: 0.00077 Loss 2.5939, Train Acc 0.1388, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1251 (Best 0.1227)\n",
      "Epoch: 45 LR: 0.00087 Loss 2.5769, Train Acc 0.1388, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1251 (Best 0.1227)\n",
      "Epoch: 50 LR: 0.00095 Loss 2.5558, Train Acc 0.1388, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1251 (Best 0.1227)\n",
      "Epoch: 55 LR: 0.00099 Loss 2.5309, Train Acc 0.1388, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1251 (Best 0.1227)\n",
      "Epoch: 60 LR: 0.00100 Loss 2.5043, Train Acc 0.1388, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1249 (Best 0.1227)\n",
      "Epoch: 65 LR: 0.00100 Loss 2.4785, Train Acc 0.1425, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1248 (Best 0.1227)\n",
      "Epoch: 70 LR: 0.00098 Loss 2.4558, Train Acc 0.1450, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1248 (Best 0.1227)\n",
      "Epoch: 75 LR: 0.00097 Loss 2.4373, Train Acc 0.1538, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1248 (Best 0.1227)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 LR: 0.00095 Loss 2.4229, Train Acc 0.1663, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1258 (Best 0.1227)\n",
      "Epoch: 85 LR: 0.00092 Loss 2.4115, Train Acc 0.1963, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1260 (Best 0.1227)\n",
      "Epoch: 90 LR: 0.00088 Loss 2.4019, Train Acc 0.2225, Val Acc 0.1000 (Best 0.1000), Test Acc 0.1294 (Best 0.1227)\n",
      "Epoch: 95 LR: 0.00085 Loss 2.3932, Train Acc 0.2450, Val Acc 0.1100 (Best 0.1100), Test Acc 0.1285 (Best 0.1285)\n",
      "Epoch: 100 LR: 0.00080 Loss 2.3850, Train Acc 0.2575, Val Acc 0.1200 (Best 0.1200), Test Acc 0.1302 (Best 0.1302)\n",
      "Epoch: 105 LR: 0.00076 Loss 2.3772, Train Acc 0.2575, Val Acc 0.1300 (Best 0.1300), Test Acc 0.1312 (Best 0.1312)\n",
      "Epoch: 110 LR: 0.00071 Loss 2.3696, Train Acc 0.2575, Val Acc 0.1200 (Best 0.1300), Test Acc 0.1336 (Best 0.1312)\n",
      "Epoch: 115 LR: 0.00065 Loss 2.3624, Train Acc 0.2612, Val Acc 0.1200 (Best 0.1300), Test Acc 0.1337 (Best 0.1312)\n",
      "Epoch: 120 LR: 0.00060 Loss 2.3556, Train Acc 0.2663, Val Acc 0.1200 (Best 0.1300), Test Acc 0.1346 (Best 0.1312)\n",
      "Epoch: 125 LR: 0.00054 Loss 2.3492, Train Acc 0.2725, Val Acc 0.1200 (Best 0.1300), Test Acc 0.1349 (Best 0.1312)\n",
      "Epoch: 130 LR: 0.00049 Loss 2.3432, Train Acc 0.2788, Val Acc 0.1200 (Best 0.1300), Test Acc 0.1352 (Best 0.1312)\n",
      "Epoch: 135 LR: 0.00043 Loss 2.3377, Train Acc 0.2812, Val Acc 0.1200 (Best 0.1300), Test Acc 0.1356 (Best 0.1312)\n",
      "Epoch: 140 LR: 0.00038 Loss 2.3328, Train Acc 0.2900, Val Acc 0.1200 (Best 0.1300), Test Acc 0.1361 (Best 0.1312)\n",
      "Epoch: 145 LR: 0.00032 Loss 2.3284, Train Acc 0.2950, Val Acc 0.1200 (Best 0.1300), Test Acc 0.1363 (Best 0.1312)\n",
      "Epoch: 150 LR: 0.00027 Loss 2.3245, Train Acc 0.2962, Val Acc 0.1200 (Best 0.1300), Test Acc 0.1364 (Best 0.1312)\n",
      "Epoch: 155 LR: 0.00022 Loss 2.3213, Train Acc 0.2950, Val Acc 0.1200 (Best 0.1300), Test Acc 0.1360 (Best 0.1312)\n",
      "Epoch: 160 LR: 0.00018 Loss 2.3186, Train Acc 0.2950, Val Acc 0.1200 (Best 0.1300), Test Acc 0.1359 (Best 0.1312)\n",
      "Epoch: 165 LR: 0.00014 Loss 2.3165, Train Acc 0.2975, Val Acc 0.1200 (Best 0.1300), Test Acc 0.1357 (Best 0.1312)\n",
      "Epoch: 170 LR: 0.00010 Loss 2.3149, Train Acc 0.2988, Val Acc 0.1100 (Best 0.1300), Test Acc 0.1357 (Best 0.1312)\n",
      "Epoch: 175 LR: 0.00007 Loss 2.3136, Train Acc 0.2988, Val Acc 0.1100 (Best 0.1300), Test Acc 0.1360 (Best 0.1312)\n",
      "Epoch: 180 LR: 0.00004 Loss 2.3128, Train Acc 0.2975, Val Acc 0.1100 (Best 0.1300), Test Acc 0.1360 (Best 0.1312)\n",
      "Epoch: 185 LR: 0.00002 Loss 2.3123, Train Acc 0.2975, Val Acc 0.1100 (Best 0.1300), Test Acc 0.1360 (Best 0.1312)\n",
      "Epoch: 190 LR: 0.00001 Loss 2.3121, Train Acc 0.2975, Val Acc 0.1100 (Best 0.1300), Test Acc 0.1361 (Best 0.1312)\n",
      "Epoch: 195 LR: 0.00000 Loss 2.3119, Train Acc 0.2975, Val Acc 0.1100 (Best 0.1300), Test Acc 0.1361 (Best 0.1312)\n",
      "Epoch: 200 LR: 0.00000 Loss 2.3119, Train Acc 0.2975, Val Acc 0.1100 (Best 0.1300), Test Acc 0.1361 (Best 0.1312)\n"
     ]
    }
   ],
   "source": [
    "!python train_acm_minibatch.py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
